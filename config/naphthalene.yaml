defaults: # which model/schedule config file to use
- model: sphnet
- schedule: polynomial 
- _self_

job_id: naphthalene # The checkpoint/log file is saved in ckpt_path/job_id
ckpt_path: outputs
seed: 123
log_dir: "outputs"
save_output_dump: false
debug: false

wandb: # wandb configuration
  open: True
  wandb_api_key: 5289f0f8d525c80f997b8e51a8f805d35bf3f602
  wandb_project: SPHNet
  wandb_group: ""
  wandb_notes: ""

#########
# trainer related config
model_backbone: SPHNet

hami_model:
  name: HamiHead_sphnet
  irreps_edge_embedding: null
  num_layer: 2
  max_radius_cutoff: 30  # hami head cut off, default full connected
  radius_embed_dim: 16
  bottle_hidden_size: 32

use_sparse_tp: true # whether use the sparse tensor product gate
sparsity: 0.3 #Sparsity ratio
num_epochs: 3000000 #Maximum number of epochs
max_steps: 100000 #Maximum number of training steps.
batch_size: 32
inference_batch_size: 1
dataloader_num_workers: 8
lr: 5e-4
multi_para_group: false
weight_decay: 0
enable_hami: true
enable_energy_hami_error: true # whether to calculate the occupiedenergy MAE and C similarity during validation. This is very slow.
enable_hami_orbital_energy: false # set it to true for WALoss
hami_train_loss: 'maemse'
hami_val_loss: 'mae'
ngpus: 1
devices: [0]
num_nodes: 1
precision: 32 # the precison for training, can use 16 for mixed precision
gradient_clip_val: 5.0
early_stopping_patience: 300000
val_check_interval: null #follow pytorch lightning
test_interval: 10 #Test interval, one test per n epochs (default: 10) # NOT used
save_interval: 1 #Save interval, one save per n epochs (default: 10)
############
# data realted config
# data_name: pubchem  #the target dataset
# basis: "def2-tzvp"  #when predict hamitonian, the basis need to be set
# dataset_path : "/data/pubchem/"  # if the dataset is lmdb format, enter the folder path

# data_name: qh9_stable_iid # four kinds of data splits: qh9_stable_iid, qh9_stable_ood, qh9_dynamic_mol, qh9_dynamic_geo
# basis: "def2-svp"
# dataset_path : "/data/qh9stable/data.mdb"     # if the dataset is mdb format, enter the file path
# # dataset_path : "/data/qh9dynamic/data.mdb"

data_name: rmd-naphthalene
basis: "def2-svp"
xc: 'pbe0'
dataset_path : "/nas/qhflow-mlff/dataset/md-naphthalene"

# data_name: custom
# basis: "def2-svp"
# dataset_path : "example_data/data.mdb"
index_path : "."

dataset_size : -1 #the dataset size is used. This will decide the steps of different phases"
train_ratio: 0.8
val_ratio: 0.1
test_ratio: 0.1
used_cache: false
ema_decay: 1 # 1 means trun off ema and (0,1) is turning on.
unit: 1 # 627.503 if the unit in the dataset is kcal/mol, else set 1; the unit used in this model is hatree
############
# model related config
activation: "silu"
remove_init: true # fock - init if remove_init else fock
remove_atomref_energy: true # when true, energy = energy - eachtype_atom_count*atom_ref
num_sanity_val_steps: 0